%%% Copyright (C) 2018 Vincent Goulet
%%%
%%% Ce fichier fait partie du projet
%%% «Méthodes numériques en actuariat avec R»
%%% http://github.com/vigou3/methodes-numeriques-en-actuariat
%%%
%%% Cette création est mise à disposition selon le contrat
%%% Attribution-Partage dans les mêmes conditions 4.0
%%% International de Creative Commons.
%%% http://creativecommons.org/licenses/by-sa/4.0/

\chapter{Simulation de nombres aléatoires non uniformes}
\label{chap:simulation}

<<echo=FALSE>>=
options(width = 52)
@

\begin{objectifs}
\item Développer un algorithme de simulation de
  nombres non uniformes à partir de la méthode de l'inverse.
\item Développer un algorithme de simulation de nombres non uniformes
  à partir de la méthode d'acceptation-rejet.
\item Calculer des nombres pseudo-aléatoires non uniformes en
  suivant un algorithme donné.
\item Utiliser les outils de Excel, VBA et R pour la simulation de
  nombres non uniformes.
\end{objectifs}

Habituellement, les applications de la simulation requièrent des
nombres aléatoires provenant non pas d'une distribution $U(0, 1)$,
mais plutôt d'une distribution avec fonction de répartition $F_X(x)$.
Ceci nécessite donc de transformer les nombres uniformes en des nombres
provenant de distributions non-uniformes.

Il existe de très nombreux algorithmes pour générer des nombres
aléatoires de différentes distributions; voir, par exemple,
\cite{Devroye:random:1986}. Nous n'en étudierons que deux en détail,
soit la méthode de l'inverse et la méthode d'acceptation-rejet.
D'autres méthodes populaires en actuariat sont mentionnées à la
\autoref{sec:simulation:autres}.

Plusieurs algorithmes de simulation de nombres non uniformes reposent
sur des résultats de transformations de variables aléatoires. Par
exemple:
\begin{itemize}
\item la somme de $\alpha$ exponentielles est une loi gamma avec
  paramètre de forme $\alpha$ entier;
\item la loi géométrique est la partie entière de l'exponentielle;
\item la loi $F$ est un ratio de deux khi-carré; etc.
\end{itemize}
Le lecteur qui ne serait pas à l'aise avec les notions de
transformation de variables aléatoires trouvera à
l'\autoref{chap:rappels_transformations} des rappels sur les
principales techniques étudiées dans les cours d'analyse probabiliste
et d'analyse statistique.

\begin{prob-enonce}
  Au chapitre précédent, nous nous sommes penchés sur le problème des
  quatre points de Sylvester lorsque la région $R$ est un carré.

  Cette fois, nous devons vérifier par simulation que lorsque la
  région $R$ est un disque, la probabilité que l'enveloppe convexe
  forme un triangle est $\frac{35}{12 \pi^2} \approx 0,29552$.
\end{prob-enonce}


\section{Méthode de l'inverse}
\label{sec:simulation:inverse}

La méthode de l'inverse repose sur une idée toute simple, soit que
l'on peut transformer des nombres uniformes sur $(0, 1)$ en des
nombres provenant de la distribution avec fonction de répartition
$F_X(x)$ en utilisant le théorème suivant.

\begin{thm}
  \label{thm:simulation:inverse}
  Soit $X$ une variable aléatoire avec fonction de répartition
  $F_X(x)$. Alors
  \begin{displaymath}
    F_X(X) \sim U(0, 1).
  \end{displaymath}
\end{thm}
\begin{proof}
  Soit la transformation $U = F_X(X)$. Alors,
  \begin{align*}
    F_U(u)
    &= \Pr[U \leq u] \\
    &= \Pr[F_X(X) \leq u] \\
    &= \Pr[X \leq F_X^{-1}(u)] \\
    &= F_X(F_X^{-1}(u)) \\
    &= u,
  \end{align*}
  d'où $U \sim U(0, 1)$.
\end{proof}

Par conséquent, si $U \sim U(0, 1)$, alors
\begin{displaymath}
  F_X^{-1}(U) \sim X.
\end{displaymath}
La fonction de répartition inverse, $F_X^{-1}$, est aussi appelée
\emph{fonction de quantile}.

La méthode de l'inverse consiste à choisir un nombre uniformément sur
l'axe des ordonnées d'une fonction de répartition (donc un nombre
entre $0$ et $1$) et à trouver la valeur correspondante sur l'axe des
abscisses telle que donnée par la fonction de quantile. Comme les
valeurs en $x$ seront plus concentrées là où la pente de la fonction
de répartition est la plus grande, et vice versa, la distribution en
abscisse ne sera pas uniforme. Voir la
\autoref{fig:simulation:inverse} pour une représentation
graphique de ce phénomène.

\begin{figure}
  \centering
<<echo=FALSE,fig=TRUE, width=8, height=4>>=
par(mfrow = c(1, 2), mar = c(5, 4, 2, 2))

## Graphique de fonction de répartition
plot(NA, xlim = c(0, 14), ylim = c(0, 1),
     xlab = expression(x), ylab = expression(F[X](x)),
     xaxs="i", yaxs="i")
u <- c(0.3, 0.4, 0.8, 0.9)
x <- qgamma(u, 5, 1)
polygon(c(0, x[1], x[1], x[2], x[2], 0),
        c(u[1], u[1], 0, 0, u[2], u[2]), col="lightblue")
polygon(c(0, x[3], x[3], x[4], x[4], 0),
        c(u[3], u[3], 0, 0, u[4], u[4]), col="lightblue")
curve(pgamma(x, 5, 1), add=TRUE)

## Graphique de la densité
plot(NA, xlim = c(0, 14), ylim = c(0, 0.2),
     xlab = expression(x), ylab = expression(f[X](x)),
     xaxs = "i", yaxs = "i")
xx <- seq(from = x[1], to = x[2], length = 100)
polygon(c(xx[1], xx, xx[100]), c(0, dgamma(xx, 5, 1), 0), col = "lightblue")
xx <- seq(from = x[3], to = x[4], length = 100)
polygon(c(xx[1], xx, xx[100]), c(0, dgamma(xx, 5, 1), 0), col = "lightblue")
curve(dgamma(x, 5, 1), xlim = c(0, 14), add=TRUE)
@
  \caption{Représentation graphique de la méthode de l'inverse. À
    des intervalles égaux en ordonnée correspondent des intervalles
    différents en abscisse selon la forme de la distribution. La
    fonction de répartition à gauche correspond à la densité de droite.}
  \label{fig:simulation:inverse}
\end{figure}

La méthode de l'inverse en est une bonne si la fonction de quantile
est facile à calculer. S'il n'existe pas de forme explicite pour
$F_X^{-1}(\cdot)$, résoudre numériquement
\begin{displaymath}
  F_X(x) - u = 0
\end{displaymath}
peut s'avérer aussi efficace que bien d'autres méthodes.

\begin{rem}
  Dans Excel (et VBA), on doit nécessairement utiliser la méthode de
  l'inverse. Plusieurs fonctions de quantiles sont disponibles
  (\autoref{sec:simulation:excel_et_al}).
\end{rem}


\subsection{Distributions continues}
\label{sec:simulation:inverse:continues}

La méthode de l'inverse est, en principe du moins, simple à utiliser
avec les distributions continues: il suffit de connaître la fonction
de quantile et de l'appliquer à des nombres uniformes pour obtenir des
nombres de la distribution souhaitée.

Dans les faits, il y a peu de lois de probabilité continues dont la
fonction de répartition est simple à inverser (exponentielle, Pareto,
Weibull). Il faut parfois utiliser d'autres méthodes.

\begin{exemple}
  On veut obtenir un échantillon aléatoire d'une distribution
  exponentielle de paramètre $\lambda$ avec fonction de densité de
  probabilité
  \begin{align*}
    f(x)
    &= \lambda e^{-\lambda x}, \quad x > 0 \\
    \intertext{et fonction de répartition}
    F(x)
    &= 1 - e^{-\lambda x}, \quad x > 0.
  \end{align*}
  Or,
  \begin{displaymath}
    F^{-1}(u) = - \frac{1}{\lambda} \ln (1 - u),
  \end{displaymath}
  donc
  \begin{displaymath}
    X = - \frac{1}{\lambda} \ln (1 - U) \sim \text{Exponentielle}(\lambda),
  \end{displaymath}
  où $U \sim U(0, 1)$. En fait, puisque $U \sim U(0, 1)
  \Leftrightarrow 1 - U \sim U(0, 1)$, on peut se contenter de la
  relation
  \begin{displaymath}
    X = - \frac{1}{\lambda} \ln U \sim \text{Exponentielle}(\lambda).
  \end{displaymath}
  Par conséquent, l'algorithme pour simuler des nombres provenant
  d'une exponentielle de paramètre $\lambda$ est:
  \begin{enumerate}
  \item Obtenir un nombre $u$ d'une $U(0, 1)$;
  \item Poser $x = - \lambda^{-1} \ln u$.
  \end{enumerate}

  \gotorbox{Exécuter le code informatique R de la
    \autoref{sec:simulation:code} correspondant à cet exemple pour une
    illustration de l'algorithme ci-dessus.}%
  \qed
\end{exemple}


\subsection{Distributions discrètes}
\label{sec:simulation:inverse:discretes}

On peut aussi utiliser la méthode de l'inverse avec les distributions
discrètes. Cependant, puisque la fonction de répartition comporte des
sauts, son inverse n'existe pas formellement. Par conséquent, il
n'existe pas de solution de $u = F_X(x)$ pour certaines valeurs de
$u$, ou alors une infinité de solutions.

Supposons une distribution avec un saut en $x_0$ et
\begin{align*}
  F_X(x_0^-) &= a \\
  F_X(x_0) &= b > a.
\end{align*}
Si $a < u < b$, on pose $x = x_0$. Ainsi, $x_0$ sera simulé dans une
proportion $b - a$ du temps, ce qui correspond à $\Pr[X = x_0]$. Voir
la \autoref{fig:simulation:discrete} pour une illustration.

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
set.seed(1)
x <- rbinom(1000, 4, 0.6)
Fn <- ecdf(x)
plot(Fn, xlim = c(0, 5), ylab="F(x)", main = "")
polygon(c(par("usr")[1], 2, 2, par("usr")[1]),
        Fn(c(1, 1, 2, 2)), col = "lightblue", border = NA)
plot(Fn, add = TRUE)
u <- runif(1, Fn(1), Fn(2))
arrows(par("usr")[1], u, 2, u, length = 0.125)
segments(2, par("usr")[3], 2, Fn(2), lty = 2)
axis(2)
@
  \caption{Illustration de la méthode de l'inverse pour une distribution
   discrète. Tout nombre uniforme tiré dans la zone colorée est
   converti en la même valeur, ce qui correspond à la probabilité
   d'obtenir cette valeur (la hauteur du saut).}
  \label{fig:simulation:discrete}
\end{figure}

Que faire si $u = a$ ou $u = b$? On prend la plus grande valeur de
l'intervalle où $F_X(x)$ est constante:
\begin{align*}
  u = a  &\Rightarrow x = x_0 \\
  u = b  &\Rightarrow x = x_1.
\end{align*}
On procède ainsi parce que plusieurs générateurs produisent des
nombres uniformes sur $[0, 1)$.

\begin{exemple}
  \label{exemple:simulation:mixte}
  Soit $X$ une variable aléatoire avec fonction de densité de probabilité
  \begin{displaymath}
    f(x) =
    \begin{cases}
      0,5, & 0 \leq x < 1 \\
      0,   & 1 \leq x < 2 \\
      0,5, & 2 \leq x < 3.
    \end{cases}
  \end{displaymath}
  On a une variable aléatoire \emph{mixte} (en partie continue et en
  partie continue) dont la fonction de répartition est
  \begin{displaymath}
    F(x) =
    \begin{cases}
      0,5x, & 0 \leq x < 1 \\
      0,5   & 1 \leq x < 2 \\
      0,5x - 0,5, & 2 \leq x < 3.
    \end{cases}
  \end{displaymath}
  \enlargethispage{5mm}
  (Voir la \autoref{fig:simulation:mixte}.)

  \begin{figure}
    \centering
<<echo=FALSE,fig=TRUE, width=8, height=4>>=
par(mfrow = c(1, 2), mar = c(5, 4, 2, 2))
plot(NA, xlim = c(0, 3), ylim = c(0, 1),
     xlab = expression(x), ylab = expression(f[X](x)),
     xaxt = "n", yaxt = "n")
points(c(0, 1), rep(0.5, 2), type = "o", pch = c(19, NA))
points(c(1, 2), rep(0, 2), type = "o", pch = c(19, NA))
points(c(2, 3), rep(0.5, 2), type = "o", pch = c(19, NA))
axis(1, at = 0:3)
axis(2, at = 0:2/2)
plot(0:3, c(0, 0.5, 0.5, 1), type = "o", pch = 19,
     xlab = expression(x), ylab = expression(F[X](x)),
     xaxt = "n", yaxt = "n")
axis(1, at = 0:3)
axis(2, at = 0:2/2)
@
    \caption{Fonction de densité de probabilité (gauche) et fonction de
      répartition (droite) de l'\autoref{exemple:simulation:mixte}}
    \label{fig:simulation:mixte}
  \end{figure}

  Par conséquent, un algorithme pour simuler des nombres aléatoires de
  cette distribution est:
  \begin{enumerate}
  \item Obtenir un nombre $u$ d'une loi $U(0, 1)$.
  \item Poser
    \begin{displaymath}
      x =
      \begin{cases}
        2u,    & \text{si } 0 \leq u < 1 \\
        2,     & \text{si } u = 0,5 \\
        2u + 1 & \text{si } 0,5 < u < 1.
      \end{cases}
    \end{displaymath}
  \end{enumerate}
  \gotorbox{Une mise en œuvre en R de l'algorithme ci-dessus est
    présentée dans le code informatique de la
    \autoref{sec:simulation:code}.}%
  \qed
\end{exemple}

\begin{exemple}
  On veut simuler des observations d'une distribution binomiale de
  paramètres $n$ et $\theta$. On pourrait, pour chaque $x$ simulé,
  faire $n$ expériences de Bernoulli et compter le nombre de succès.
  Par la méthode de l'inverse pour la loi de Bernoulli, on a un succès
  si $u \leq \theta$. Par conséquent, un algorithme serait:
  \begin{enumerate}
  \item Simuler $n$ nombres uniformes indépendants $u_1, \dots, u_n$
    d'une loi $U(0, 1)$.
  \item Poser
    \begin{displaymath}
      x = \sum_{i = 1}^n I\{u_i \leq \theta\}.
    \end{displaymath}
  \end{enumerate}
  Cette technique requiert toutefois de simuler $n$ nombres uniformes
  pour chaque valeur de $x$.

  Il est plus efficace d'utiliser la méthode de l'inverse directement
  avec la distribution binomiale. Par exemple, si $n = 4$ et $\theta =
  0,5$, on a que
  \begin{align*}
    \Pr[X = x]
    &=
    \begin{cases}
      0,0625, & x = 0 \\
      0,25,   & x = 1 \\
      0,375,  & x = 2 \\
      0,25,   & x = 3 \\
      0,0625, & x = 4
    \end{cases} \\
    \intertext{et}
    \Pr[X \leq x]
    &=
    \begin{cases}
      0,      & x < 0 \\
      0,0625, & 0 \leq x < 1 \\
      0,3125, & 1 \leq x < 2 \\
      0,6875, & 2 \leq x < 3 \\
      0,9375, & 3 \leq x < 4 \\
      1,      & x \geq 4,
    \end{cases}
  \end{align*}
  d'où l'algorithme suivant:
  \begin{enumerate}
  \item Simuler un nombre $u$ d'une distribution $U(0, 1)$.
  \item Déterminer $x$ selon le tableau suivant:
    \begin{center}
      \begin{tabular}{lc}
        \toprule
        $u$ dans l'intervalle & Valeur de $x$ \\
        \midrule
        $[0, 0,0625)$         & $0$ \\
        $[0,0625, 0,3125)$    & $1$ \\
        $[0,3125, 0,6875)$    & $2$ \\
        $[0,6875, 0,9375)$    & $3$ \\
        $[0,9375, 1)$         & $4$ \\
        \bottomrule
      \end{tabular}
    \end{center}
  \end{enumerate}
  \qed
\end{exemple}

\begin{rem}
  La méthode de l'inverse pour les distributions discrètes à support
  fini est facile à mettre en œuvre dans Excel à l'aide de la
  fonction \texttt{RECHERCHEV()}.
\end{rem}

\begin{prob-astuce}
  Au cœur du problème que nous tentons de résoudre, il y a la
  simulation de points dans un cercle. L'interprétation géométrique
  est claire.

  Il serait également possible d'en faire une interprétation
  probabiliste: nous voulons simuler des valeurs d'une distribution
  bidimensionnelle uniforme sur un disque --- sans perte de
  généralité, de rayon $1$ et centré à l'origine --- dont la fonction
  de densité conjointe est
  \begin{equation*}
    f_{XY}(x, y) = \frac{1}{\pi}, \quad -1 < x < 1,\, x^2 + y^2 < 1.
  \end{equation*}
  Cependant, les méthodes de simulation pour les distributions
  multidimensionnelles deviennent rapidement complexes, surtout
  lorsque les variables ne sont pas indépendantes, comme c'est le cas
  ici. Nous tâcherons donc de trouver une manière plus intuitive d'un
  point de vue géométrique pour simuler des points sur un disque.
\end{prob-astuce}


\section{Méthode acceptation-rejet}

Supposons qu'il est compliqué de simuler des réalisations de la
variable aléatoire $X$ avec fonction de densité de probabilité
$f_X(x)$. Si on peut trouver une variable aléatoire $Y$ avec fonction
de densité de probabilité $g_Y(x)$ pour laquelle la simulation est
simple (uniforme, triangle, exponentielle, etc.) et qu'il est possible
d'«envelopper» la densité $f$ par un multiple de $g$, c'est-à-dire que
\begin{displaymath}
  c g_Y(x) \geq f_X(x)
\end{displaymath}
pour tout $x$, alors on a l'algorithme d'acceptation-rejet suivant:
\begin{enumerate}
\item Générer une réalisation $y$ de la variable aléatoire $Y$ avec
  fonction de densité de probabilité $g_Y(\cdot)$.
\item Générer un nombre $u$ d'une $U(0, 1)$.
\item Si
  \begin{displaymath}
    u \leq \frac{f_X(y)}{c g_Y(y)},
  \end{displaymath}
  poser $x = y$. Sinon, retourner à l'étape 1.
\end{enumerate}

\begin{rem}
  Puisque, par définition, l'aire sous les densités $f$ et $g$ vaut $1$
  dans les deux cas on ne peut avoir $c g_Y(x) \geq f_X(x)$ pour tout
  $x$ que si $c > 1$.
\end{rem}

L'idée de la %
\capsule{http://youtu.be/acceptation-rejet}{méthode
  d'acceptation-rejet} %
consiste à accepter la «bonne proportion» des réalisations de $Y$
comme provenant de $X$. Dans l'illustration de la
\autoref{fig:simulation:acceptation-rejet}, la densité $f$ à support
fini est facilement enveloppée par un rectangle. Un nombre $y$ simulé
de cette distribution (à toutes fins pratiques une uniforme, ici) est
accepté comme provenant de $f$ dans une proportion correspondant au
ratio entre la valeur de $f_X(y)$ (les segments pointillés dans la
figure) et la valeur de $c g_Y(y)$ (les segments pleins). On constate
aisément que certaines valeurs $y$ seront acceptées plus souvent que
d'autres en conformité avec la forme de la densité.

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
## plot(NA, xlim = c(0, 1), ylim = c(0, 2), xlab = "y", ylab = "f(y)")
## m <- dbeta(2/3, 3, 2)
## x <- rep(c(0.22, 0.58, 0.83), each = 8)
## y <- runif(24, 0, m)
## points(x, y, pch = ifelse(y <= dbeta(x, 3, 2), 21, 1), bg = "darkgray")
## curve(dbeta(x, 3, 2), xlim = c(0, 1), add = TRUE, lwd = 2, col = "blue3")
## segments(0, m, 1, m, col = "red3", lwd = 2)
plot(NA, xlim = c(0, 1), ylim = c(0, 2), xlab = "y", ylab = "f(y)")
m <- dbeta(2/3, 3, 2)
x <- c(0.22, 0.58, 0.83)
eps <- eps <- 30E-4
segments(x - eps, 0, x - eps, dbeta(x, 3, 2), col = "lightblue", lwd = 3, lty = 2)
segments(x + eps, 0, x + eps, m, col = "lightblue", lwd = 3)
curve(dbeta(x, 3, 2), xlim = c(0, 1), add = TRUE, lwd = 2, col = "black")
segments(0, m, 1, m, col = "orange", lwd = 2)
text(0.1, m + 0.08, "c g(y)")
@
  \caption{Illustration de la méthode acceptation-rejet}
  \label{fig:simulation:acceptation-rejet}
\end{figure}

Une autre interprétation est possible. La méthode dit d'accepter la
valeur $y$ simulée de la densité $g$ comme provenant de la densité $f$
si
\begin{equation*}
  u c g_Y(y) \leq f_X(y),
\end{equation*}
où $u$ est un nombre issu d'une loi $U(0, 1)$. Graphiquement, cela
signifie que l'on accepte la valeur $y$ si le point $(y, u c g_Y(y))$
se trouve sous la courbe $f$ en $y$ et qu'on le rejette s'il se trouve
entre $f$ et l'enveloppe. La
\autoref{fig:simulation:acceptation-rejet2} illustre cette
interprétation.

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
## plot(NA, xlim = c(0, 1), ylim = c(0, 2), xlab = "y", ylab = "f(y)")
## m <- dbeta(2/3, 3, 2)
## x <- rep(c(0.22, 0.58, 0.83), each = 8)
## y <- runif(24, 0, m)
## points(x, y, pch = ifelse(y <= dbeta(x, 3, 2), 21, 1), bg = "darkgray")
## curve(dbeta(x, 3, 2), xlim = c(0, 1), add = TRUE, lwd = 2, col = "blue3")
## segments(0, m, 1, m, col = "red3", lwd = 2)
m <- dbeta(2/3, 3, 2)
x <- runif(100)
mu <- m * runif(100)
plot(x, mu, xlim = c(0, 1), ylim = c(0, 2), xlab = "y", ylab = "f(y)",
     pch = ifelse(mu <= dbeta(x, 3, 2), 21, 1), bg = "lightblue")
curve(dbeta(x, 3, 2), xlim = c(0, 1), add = TRUE, lwd = 2, col = "black")
segments(0, m, 1, m, col = "orange", lwd = 2)
text(0.1, m + 0.08, "c g(y)")
@
  \caption{Interprétation alternative de la méthode acceptation-rejet.
    Chaque point représente un couple $(y, u c g_Y(y))$. On accepte les
    points pleins et on rejette les points vides.}
  \label{fig:simulation:acceptation-rejet2}
\end{figure}

\begin{rems}
  \begin{enumerate}
  \item La principale difficulté avec la méthode d'acceptation-rejet
    consiste à trouver la fonction enveloppante $c g_Y(x)$.
  \item Évidemment, plus l'enveloppe est près de $f_X(x)$, plus
    l'algorithme est performant puisque l'on rejette alors moins de
    valeurs.
  \item Il est aussi possible d'envelopper une densité à support
    infini\dots\ par une autre densité à support fini; voir les
    exercices.
  \end{enumerate}
\end{rems}

\begin{exemple}
  \label{exemple:simulation:beta:1}
  Soit $X \sim \text{Bêta}(3, 2)$. On a
  \begin{align*}
    f_X(x)
    &= \frac{\Gamma(5)}{\Gamma(3) \Gamma(2)}\,
    x^{3 - 1} (1 - x)^{2 - 1} \\
    &= 12 x^2 (1 - x), \quad 0 < x < 1.
  \end{align*}
  C'est la densité représentée aux figures
  \ref{fig:simulation:acceptation-rejet} et
  \ref{fig:simulation:acceptation-rejet2}. On l'inscrit facilement
  dans un rectangle. Le mode de la densité se trouvant en $x = 2/3$,
  la hauteur du rectangle est $f(2/3) = 48/27 = 16/9$. Par conséquent,
  \begin{displaymath}
    c g_Y(x) = \frac{16}{9}, \quad 0 < x < 1.
  \end{displaymath}
  On déduit que $c = 16/9$ et que la densité $g$ est une uniforme sur
  $(0 , 1)$. On a donc l'algorithme suivant:
  \begin{enumerate}
  \item Simuler deux nombres $u_1$ et $u_2$ d'une $U(0, 1)$.
  \item Poser $y = u_1$.
  \item Si
    \begin{displaymath}
      u_2 \leq \frac{f_X(y)}{16/9},
    \end{displaymath}
    alors poser $x = y$. Sinon, retourner à l'étape 1.
  \end{enumerate}

  L'aire du rectangle étant de $16/9$, on peut s'attendre
  à rejeter
  \begin{equation*}
    \frac{16/9 - 1}{16/9} = \frac{7}{16} \approx 44~\%
  \end{equation*}
  des nombres $u_1$ simulés à l'étape~1 de
  l'algorithme ci-dessus. Si l'enveloppe
  était plus «serrée» autour de la densité, l'efficacité de
  l'algorithme en serait augmentée.
  \qed
\end{exemple}

\begin{exemple}
  \label{exemple:simulation:beta:2}
  On reprend l'\autoref{exemple:simulation:beta:1} en tentant
  d'améliorer l'efficacité de l'algorithme. Il s'avère que l'on peut
  inscrire la densité de la loi Bêta$(3, 2)$ dans un triangle aux
  caractéristiques suivantes (voir la
  \autoref{fig:simulation:beta-triangle}):
  \begin{figure}
    \centering
<<echo=FALSE, fig=TRUE>>=
curve(dbeta(x, 3, 2), xlim = c(0, 1), ylim = c(0, 2.5), col = "black", lwd = 2)
lines(c(0, 0.8, 1), c(0, 2.4, 0), lwd = 2, col = "orange")
segments(0.5, 0, 0.5, 1.5, col = "lightblue", lwd = 2, lty = 3)
segments(0.8, 0, 0.8, 2.4, col = "lightblue", lwd = 2, lty = 3)
axis(side = 1, at = 0.5)
@
    \caption{Fonction de densité de probabilité d'une loi Bêta$(3, 2)$
      enveloppée d'un triangle}
    \label{fig:simulation:beta-triangle}
  \end{figure}
  \begin{enumerate}
  \item l'arête gauche passe par $(0, 0)$, donc est de la forme $y =
    mx$. Cette droite étant tangente à $f(x)$, la pente $m$ est telle
    que l'équation $mx = 12 x^2 (1 - x)$ a une seule racine autre que
    $0$, d'où $y = 3 x$;
  \item l'arête droite passe par $(1, 0)$, donc est de la forme $y =
    mx + b$ avec $m + b = 0$. Comme la pente de cette droite est égale
    à la pente de $f(x)$ en $x = 1$, on trouve que $y = 12 - 12 x$.
  \end{enumerate}
  Ainsi,
  \begin{displaymath}
    c g_Y(x) =
    \begin{cases}
      3x,       & 0 < x < 0,8 \\
      12 - 12 x, & 0,8 < x < 1.
    \end{cases}
  \end{displaymath}
  Or, l'aire du triangle est
  \begin{displaymath}
    \frac{(1) c g_Y(0,8)}{2} = \frac{(1)(2,4)}{2} = 1,2,
  \end{displaymath}
  d'où $c = 1,2$. Par conséquent,
  \begin{align*}
    g_Y(x)
    &=
    \begin{cases}
      2,5 x,     & 0 < x < 0,8 \\
      10 - 10 x, & 0,8 < x < 1.
    \end{cases}
  \end{align*}
  Pour simuler des observations de cette densité par la méthode de
  l'inverse, on calcule la fonction de répartition correspondante
  \begin{align*}
    G_Y(x)
    &=
    \begin{cases}
      1,25 x^2,          & 0 < x < 0,8 \\
      -5 x^2 + 10 x - 4, & 0,8 < x < 1,
    \end{cases} \\
    \intertext{d'où}
    G_Y^{-1}(y)
    &=
    \begin{cases}
      \sqrt{0,8 y},           & 0 < y < 0,8 \\
      1 - \sqrt{0,2 - 0,2 y}, & 0,8 < y < 1.
    \end{cases}
  \end{align*}
  Au final, on a l'algorithme suivant:
  \begin{enumerate}
  \item Simuler deux nombres $u_1$ et $u_2$ d'une $U(0, 1)$.
  \item Poser $y = G_Y^{-1}(u_1)$.
  \item Si
    \begin{displaymath}
      u_2 \leq \frac{f_X(y)}{1,2 g_Y(y)} \Leftrightarrow
      1,2 g_Y(y) u_2 \leq f_X(y),
    \end{displaymath}
    alors poser $x = y$. Sinon, retourner à l'étape 1.
  \end{enumerate}

  L'aire du triangle étant de $1,2$, on peut maintenant s'attendre à
  ne rejeter que $0,2/1,2 \approx 17~\%$ des nombres simulés, une amélioration
  importante par rapport à l'\autoref{exemple:simulation:beta:1}. %
  \qed
\end{exemple}

\begin{prob-astuce}
  \label{astuce:simulation:2}
  L'interprétation géométrique de la méthode d'acceptation-rejet
  illustrée à la \autoref{fig:simulation:acceptation-rejet2} nous met
  sur la piste d'une manière simple de générer des points distribués
  uniformément sur un disque.

  En effet, il suffit de simuler des points uniformément sur un carré
  comme nous l'avons déjà fait au \autoref{chap:generation}, puis de
  rejeter ceux qui ne se trouvent pas à l'intérieur du disque. La
  \autoref{fig:simulation:disque} illustre cette idée: nous
  accepterions les points pleins et nous rejetterions les points
  vides.
\end{prob-astuce}

\begin{figure}
  \centering
<<echo=FALSE, fig=TRUE>>=
x <- runif(200, -1, 1)
y <- runif(200, -1, 1)
w <- x^2 + y^2 < 1
t <- seq(0, 2 * pi, length = 1000)

plot(x, y, xlab="x", ylab="y", xlim=c(-1, 1), ylim=c(-1, 1),
     pch = ifelse(w, 21, 1), bg = "lightblue")
#points(x[!w], y[!w], xlab="x", ylab="y", pch = 1)
lines(x = cos(t), y = sin(t), col = "black", lwd = 2)
rect(-1, -1, 1, 1, border = "orange", lwd = 2)
@
  \caption{Simulation de points sur un disque par une méthode d'acceptation-rejet}
  \label{fig:simulation:disque}
\end{figure}


\section{Fonctions de simulation de variables aléatoires dans Excel,
  VBA et \textsf{R}}
\label{sec:simulation:excel_et_al}

Il est important de savoir simuler des valeurs d'une variable
aléatoire quelconque à partir de la méthode de l'inverse ou d'un autre
algorithme, surtout si la distribution de la variable aléatoire est
peu usitée. Néanmoins, les différents outils statistiques fournissent
en général la majorité des fonctions de simulation de variables
aléatoires dont on peut avoir besoin pour un usage quotidien.


\subsection{Excel et VBA}

Tel que mentionné à la section 3.1, il faut généralement utiliser la
méthode de l'inverse pour simuler des observations de lois de
probabilité dans Excel. Cette procédure est facilitée par le fait
qu'il existe des fonctions Excel pour calculer la fonction de
répartition inverse (ou fonction de quantile) des lois les plus
courantes.

Ainsi, on trouvera dans Excel la fonction de densité de probabilité
(lois continues) ou la fonction de masse de probabilité (lois
discrètes) ou la fonction de répartition et, dans certains cas
seulement, la fonction de quantile des lois de probabilité présentées
au \autoref{tab:excel}. Les noms anglais des fonctions ont été
modifiés pour être standardisés dans Excel~2010. On remarquera que les
traducteurs français ont omis de faire de même.

\begin{table}[t]
  \centering
  \begin{tabularx}{\linewidth}{lp{17ex}X}
    \toprule
    Loi de probabilité &
    Fonctions Excel \newline (nom anglais) &
    Fonctions Excel \newline (nom français) \\
    \midrule
    Bêta &
    \code{BETA.DIST} \newline \code{BETA.INV} &
    \code{LOI.BETA.N} \newline \code{BETA.INVERSE.N} \\
    Binomiale &
    \code{BINOM.DIST} \newline \code{BINOM.INV} &
    \code{LOI.BINOMALE.N} \newline \code{LOI.BINOMIALE.INVERSE} \\
    Binomiale négative &
    \code{NEGBINOM.DIST} &
    \code{LOI.BINOMIALE.NEG.N} \\
    Exponentielle &
    \code{EXPON.DIST} &
    \code{LOI.EXPONENTIELLE.N} \\
    \emph{F} (Fisher) &
    \code{F.DIST} \newline \code{F.INV} &
    \code{LOI.F.N} \newline \code{INVERSE.LOI.F.N} \\
    Gamma &
    \code{GAMMA.DIST} \newline \code{GAMMA.INV} &
    \code{LOI.GAMMA.N} \newline \code{LOI.GAMMA.INVERSE.N} \\
    Hypergéométrique &
    \code{HYPGEOM.DIST} &
    \code{LOI.HYPERGEOMETRIQUE.N} \\
    Khi carré &
    \code{CHISQ.DIST} \newline \code{CHISQ.INV} &
    \code{LOI.KHIDEUX} \newline \code{LOI.KHIDEUX.INVERSE} \\
    Log-normale &
    \code{LOGNORM.DIST} \newline \code{LOGNORM.INV} &
    \code{LOI.LOGNORMALE.N} \newline \code{LOI.LOGNORMALE.INVERSE.N} \\
    Normale &
    \code{NORM.DIST} \newline
    \code{NORM.INV} \newline
    \code{NORM.S.DIST} \newline
    \code{NORM.S.INV} &
    \code{LOI.NORMALE.N} \newline
    \code{LOI.NORMALE.INVERSE.N} \newline
    \code{LOI.NORMALE.STANDARD.N} \newline
    \code{LOI.NORMALE.STANDARD.INVERSE.N} \\
    Poisson &
    \code{POISSON.DIST} &
    \code{LOI.POISSON.N} \\
    \emph{t} (Student) &
    \code{T.DIST} \newline \code{T.INV} &
    \code{LOI.STUDENT.N} \newline \code{LOI.STUDENT.INVERSE.N} \\
    Weibull &
    \code{WEIBULL.DIST} &
    \code{LOI.WEIBULL.N} \\
    \bottomrule
  \end{tabularx}
  \caption{Liste des fonctions relatives à des lois de probabilité
    depuis Excel 2010.}
  \label{tab:excel}
\end{table}

Aucune fonction statistique n'existe dans VBA. On fera donc appel aux
fonctions de Excel en préfixant les noms de fonctions \emph{anglais}
du \autoref{tab:excel} de la propriété \code{WorksheetFunction}.
En utilisant une structure
\begin{verbatim}
With WorksheetFunction
    ...
End With
\end{verbatim}
dans une routine VBA, il est également possible accéder directement
aux fonctions Excel en les préfixant seulement d'un point.


\subsection{R}

Un large éventail de fonctions donne directement accès aux
caractéristiques de plusieurs lois de probabilité dans R. Pour chaque
racine \code{\meta{loi}}, il existe quatre fonctions différentes :
\begin{enumerate}
\item \code{d\meta{loi}} calcule la fonction de densité de
  probabilité (loi continue) ou la fonction de masse de probabilité
  (loi discrète);
\item \code{p\meta{loi}} calcule la fonction de répartition;
\item \code{q\meta{loi}} calcule la fonction de quantile;
\item \code{r\meta{loi}} simule des observations de cette loi.
\end{enumerate}

Les différentes lois de probabilité disponibles dans le système R de
base, leur racine et le nom de leurs paramètres sont rassemblés au
\autoref{tab:rng:lois}. Des paquetages fournissent des fonctions
pour d'autres lois dont, entre autres, \pkg{actuar} \citep{actuar} et
\pkg{SuppDists} \citep{Rpackage:SuppDists}.

\begin{table}
  \centering
  \begin{tabular}{lll}
    \toprule
    Loi de probabilité & Racine dans R & Noms des paramètres \\
    \midrule
    Bêta & \code{beta} & \code{shape1}, \code{shape2} \\
    Binomiale & \code{binom} & \code{size}, \code{prob} \\
    Binomiale négative & \code{nbinom} & \code{size},
    \code{prob} ou \code{mu} \\
    Cauchy & \code{cauchy} & \code{location}, \code{scale} \\
    Exponentielle & \code{exp} & \code{rate} \\
    \emph{F} (Fisher) & \code{f} & \code{df1}, \code{df2} \\
    Gamma & \code{gamma} & \code{shape}, \code{rate} ou
    \code{scale} \\
    Géométrique & \code{geom} & \code{prob} \\
    Hypergéométrique & \code{hyper} & \code{m}, \code{n},
    \code{k} \\
    Khi carré & \code{chisq} & \code{df} \\
    Logistique & \code{logis} & \code{location}, \code{scale} \\
    Log-normale & \code{lnorm} & \code{meanlog}, \code{sdlog} \\
    Normale & \code{norm} & \code{mean}, \code{sd} \\
    Poisson & \code{pois} & \code{lambda} \\
    \emph{t} (Student) & \code{t} & \code{df} \\
    Uniforme & \code{unif} & \code{min}, \code{max} \\
    Weibull & \code{weibull} & \code{shape}, \code{scale} \\
    Wilcoxon & \code{wilcox} & \code{m}, \code{n} \\
    \bottomrule
  \end{tabular}
  \caption{Lois de probabilité pour lesquelles il existe des fonctions
    dans le système R de base}
  \label{tab:rng:lois}
\end{table}

Toutes les fonctions du \autoref{tab:rng:lois} sont vectorielles,
c'est-à-dire qu'elles acceptent en argument un vecteur de points où la
fonction (de densité, de répartition ou de quantile) doit être évaluée
et même un vecteur de paramètres. Par exemple,
<<echo=TRUE>>=
dpois(c(3, 0, 8), lambda = c(1, 4, 10))
@
retourne la probabilité que des lois de Poisson de paramètre $1$, $4$ et
$10$ prennent les valeurs $3$, $0$ et $8$, dans l'ordre.

Le premier argument de toutes les fonctions de simulation est la
quantité de nombres aléatoires désirée. Ainsi,
<<echo=TRUE>>=
rpois(3, lambda = c(1, 4, 10))
@
retourne trois nombres aléatoires issus de distributions de Poisson
de paramètre $1$, $4$ et $10$, respectivement.  Évidemment, passer un
vecteur comme premier argument n'a pas tellement de sens, mais, si
c'est fait, R retournera une quantité de nombres aléatoires égale à la
\emph{longueur} du vecteur (sans égard aux valeurs contenues dans le
vecteur).

La fonction \code{sample} permet de simuler des nombres d'une
distribution discrète quelconque. Sa syntaxe est
\begin{quote}
  \code{sample(x, size, replace = FALSE, prob = NULL)},
\end{quote}
où \code{x} est un vecteur des valeurs possibles de l'échantillon à
simuler (le support de la distribution), \code{size} est la quantité
de nombres à simuler et \code{prob} est un vecteur de probabilités
associées à chaque valeur de \code{x} (\code{1/length(x)} par défaut).
Enfin, si \code{replace} est \code{TRUE}, l'échantillonnage se fait
avec remise.

\gotorbox{Le code informatique R de la \autoref{sec:simulation:code}
  contient des exemples plus détaillés d'utilisation des fonctions
  mentionnées ci-dessus.}



\section{Autres techniques de simulation}
\label{sec:simulation:autres}

Il existe plusieurs autres algorithmes de simulation de loi non
uniformes, certains beaucoup plus élaborés que d'autres. Nous
n'irons pas plus loin dans ce sujet dans ce cours, sinon pour
mentionner deux autres techniques simples qui sont souvent employées
en actuariat:
\begin{enumerate}
\item les mélanges de distributions continus et discrets;
\item la convolution de variables aléatoires.
\end{enumerate}

\gotorbox{Ces techniques sont présentées et illustrées à même le code
  informatique R de la \autoref{sec:simulation:code}.}

En terminant, mentionnons que l'\autoref{planification} propose
quelques trucs pour bien planifier une étude de simulation en R.

\begin{figure}
  \centering
  \begin{framed}
\begin{lstlisting}
sim.disque <- function(n)
{
    ## La fonction retourne les coordonnées des points
    ## dans une matrice de deux colonnes. On crée
    ## d'abord un contenant.
    X <- matrix(NA, n, 2)

    ## Remplissage de la matrice.
    i <- 1
    repeat
    {
        ## Simulation de coordonnées dans un carré
        ## 2 x 2 centré à l'origine.
        x <- runif(2, -1, 1)

        ## Si les coordonnées sont dans le disque...
        if (sum(x^2) < 1)
        {
            ## ... on ajoute la paire à la matrice 'X'.
            X[i, ] <- x

            ## On cesse après avoir accepté 'n' paires.
            if (n < (i <- i + 1))
                break
        }
    }
    X
}
\end{lstlisting}
  \end{framed}
  \caption{Code d'une fonction pour simuler des nombres uniformément
    sur un disque de rayon $1$ centré à l'origine par la méthode
    d'acceptation-rejet}
  \label{fig:simulation:sim.disque}
\end{figure}

\begin{prob-solution}
  Nous adoptons la stratégie expliquée à l'astuce de la
  \autopageref{astuce:simulation:2}. La fonction R de la
  \autoref{fig:simulation:sim.disque} genère des points distribués
  uniformément sur un disque par la méthode d'acceptation-rejet en
  simulant d'abord des points sur un carré.

  Avec en mains cette fonction, il devient simple de vérifier par
  simulation la probabilité $\frac{35}{12 \pi^2} \approx 0,29552$ en
  procédant comme au \autoref{chap:generation}:
<<echo=FALSE>>=
sim.disque <- function(n)
{
    X <- matrix(NA, n, 2)

    i <- 1
    repeat
    {
        x <- runif(2, -1, 1)

        if (sum(x^2) < 1)
        {
            X[i, ] <- x
            if (n < (i <- i + 1))
                break
        }
    }
    X
}
@
<<<echo=TRUE>>=
mean(replicate(1E5, 3 == length(chull(sim.disque(4)))))
@

  Une autre stratégie de simulation se révèle toutefois plus efficace. Elle
  repose sur la simulation des coordonnées polaires (rayon et angle)
  des points sur le disque, puis de leur transformation en coordonnées
  cartésiennes. Si un point du disque unité centré à l'origine se trouve à
  un rayon $r < 1$ du centre et à un angle $\theta$ de l'horizontale,
  alors ses coordonnées cartésiennes sont
  \begin{align*}
    x &= \sqrt{r} \cos \theta \\
    y &= \sqrt{r} \sin \theta.
  \end{align*}
  La \autoref{fig:simulation:sim.disque2} propose une
  mise en œuvre de cette méthode en R. La démonstration de la
  validité de cette méthode fait quant à elle l'objet de
  l'\autoref{ex:simulation:disque}.

  Parce qu'elle ne requiert aucune boucle, cette seconde méthode est
  \emph{beaucoup} plus rapide que la méthode d'acceptation-rejet:
<<echo=FALSE>>=
sim.disque2 <- function(n)
{
    r <- runif(n)
    angle <- runif(n, 0, 2 * pi)
    sqrt(r) * cbind(cos(angle), sin(angle))
}
@
<<echo=TRUE>>=
system.time(sim.disque(1E5))
system.time(sim.disque2(1E5))
@
\end{prob-solution}

\begin{figure}
  \centering
  \begin{framed}
\begin{lstlisting}
sim.disque2 <- function(n)
{
    ## Simulation des coordonnées polaires
    r <- runif(n)                       # rayon
    angle <- runif(n, 0, 2 * pi)        # angle

    ## Transformation en coordonnées cartésiennes
    sqrt(r) * cbind(cos(angle), sin(angle))
}
\end{lstlisting}
  \end{framed}
  \caption{Code d'une fonction pour simuler des nombres uniformément
    sur un disque de rayon $1$ centré à l'origine en passant par les
    coordonnées polaires}
  \label{fig:simulation:sim.disque2}
\end{figure}


\section{Code informatique}
\label{sec:simulation:code}

\def\scriptfilename{simulation.R}

\scriptfile{\scriptfilename}
\lstinputlisting[firstline=13]{\scriptfilename}


\section{Exercices}
\label{sec:simulation:exercices}

\Opensolutionfile{reponses}[reponses-simulation]
\Opensolutionfile{solutions}[solutions-simulation]

\begin{Filesave}{reponses}
\bigskip
\section*{Réponses}

\end{Filesave}

\begin{Filesave}{solutions}
\section*{Chapitre \ref*{chap:simulation}}
\addcontentsline{toc}{section}{Chapitre \ref*{chap:simulation}}

\end{Filesave}

Les étudiants jugent souvent que les exercices de ce chapitre sont
plus difficiles que ceux des autres chapitres. Les exercices font
beaucoup appel à des notions de transformations de variables
aléatoires qui ont pourtant déjà fait l'objet d'autres cours. Pour un
rappel des principaux résultats dans ce domaine, consulter
l'\autoref{chap:rappels_transformations}.

\begin{exercice}
  La transformation de Box--Muller est populaire pour simuler des
  nombres normaux à partir de nombres uniformes. Soit $U_1 \sim U(0,
  1)$ et $U_2 \sim U(0, 1)$ deux variables aléatoires indépendantes et
  \begin{align*}
    X_1 &= (-2 \log U_1)^{1/2} \cos (2\pi U_2) \\
    X_2 &= (-2 \log U_1)^{1/2} \sin (2\pi U_2).
  \end{align*}
  \begin{enumerate}
  \item Vérifier de manière heuristique que la transformation
    ci-dessus est bijective de $\{(u_1, u_2); 0 < u_1 < 1, 0 < u_2 <
    1\}$ à $\{(x_1, x_2); -\infty < x_1 < \infty, -\infty < x_2 <
    \infty\}$, c'est-à-dire qu'elle associe à un point $(u_1, u_2)$ un
    et un seul point $(x_1, x_2)$.
  \item Démontrer que la transformation inverse est
    \begin{align*}
      U_1 &= e^{-(X_1^2 + X_2^2)/2} \\
      U_2 &= \frac{1}{2 \pi} \arctan \frac{X_2}{X_1}.
    \end{align*}
  \item Démontrer que $X_1$ et $X_2$ sont deux variables aléatoires
    indépendantes chacune distribuée selon une $N(0, 1)$.
  \item Vérifier empiriquement la validité de ces formules à l'aide de
    Excel ou R. En R, on peut transformer les nombres uniformes
    obtenus avec la fonction \code{runif} en nombres normaux sans même
    utiliser de boucles grâce à la fonction \code{outer} et deux
    fonctions anonymes.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Tout d'abord, on voit que
      \begin{align*}
        \cos (2\pi U_{2}) &\in (-1, 1) \\
        \sin (2\pi U_{2}) &\in (-1, 1) \\
        \intertext{et}
        (-2 \log U_1)^{1/2} &\in (0, \infty).
      \end{align*}
      Par conséquent, $X_1 \in (-\infty, \infty)$ et $X_2 \in
      (-\infty, \infty)$. On vérifie la bijectivité de façon
      heuristique avec quelques valeurs de $u_1$ et $u_2$.
    \item On a
      \begin{align*}
        X_1^2 &= (-2 \log U_1) \cos^2 (2\pi U_2) \\
        X_2^2 &= (-2 \log U_1) \sin^2 (2\pi U_2).
      \end{align*}
      Or, puisque $\sin^{2}(x) + \cos^{2}(x) = 1$, $X_1^2 + x_2^2 = -2
      \log U_1$, d'où $U_1 = e^{-(X_1^2 + X_2^2)/2}$. D'autre part,
      $\sin(x)/\cos(x) = \tan(x)$, donc $\tan (2\pi U_2) = X_2/X_1$
      ou, de manière équivalente, $U_2 = (2 \pi)^{-1} \arctan
      X_2/X_1$.
    \item Soit les fonctions
      \begin{align*}
        x_1(u_1, u_2)
        &= (-2\log u_1)^{1/2} \cos (2\pi u_2)  &
        u_1(x_1,x_2)
        &= e^{-(x_1^2 + x_2^2)/2}  \\
        x_2(u_1, u_2)
        &= (-2\log u_1)^{1/2} \sin (2\pi u_2) &
        u_2(x_1, x_2)
        &= \frac{1}{2\pi} \arctan \frac{x_2}{x_1}.
      \end{align*}
      Les variables aléatoires $U_1$ et $U_2$ sont indépendantes, donc
      leur fonction de densité de probabilité conjointe est le produit
      des densités marginales:
      \begin{displaymath}
        f_{U_1, U_2}(u_1, u_2) = 1, \quad 0 < u_1 < 1, 0 < u_2 < 1.
      \end{displaymath}
      La densité conjointe de $X_1$ et $X_2$ est, par définition d'une
      transformation,
      \begin{displaymath}
        f_{X_1,X_2}(x_1, x_2) =
        f_{U_1, U_2}(x_1(u_1, u_2), x_2(u_1,u_2)) |\det(J)|,
      \end{displaymath}%
      où
      \begin{equation*}
        J =
        \begin{bmatrix}
          \dfrac{\partial u_1}{\partial x_1} &
          \dfrac{\partial u_1}{\partial x_2} \\[6pt]
          \dfrac{\partial u_2}{\partial x_1} &
          \dfrac{\partial u_2}{\partial x_2}
        \end{bmatrix} =
        \begin{bmatrix}
          -x_1 e^{- (x_1^2 + x_2^2)/2} &
          -x_2 e^{- (x_1^2 + x_2^2)/2} \\[6pt]
          -\dfrac{1}{2\pi} \dfrac{x_2}{x_1^2 + x_2^2} &
          \dfrac{1}{2\pi} \dfrac{x_1}{x_1^2 + x_2^2}
        \end{bmatrix}.
      \end{equation*}
      Or,
      \begin{align*}
        |\det(J)|
        &= \frac{1}{2\pi}\, e^{-(x_1^2 + x_2^2)/2} \\
        &= \frac{1}{\sqrt{2\pi}}\, e^{-x_1^2/2} \cdot
        \frac{1}{\sqrt{2\pi}} e^{-x_2^2/2},
      \end{align*}
      d'où
      \begin{displaymath}
        f_{X_1,X_2}(x_1, x_2) = \frac{1}{\sqrt{2\pi}} e^{-x_1^2/2} \cdot
        \frac{1}{\sqrt{2\pi}} e^{-x_2^2/2}.
      \end{displaymath}
      Par conséquent, $X_1$ et $X_2$ sont deux variables aléatoires $N(0, 1)$
      indépendantes.
    \item
<<echo=TRUE, eval=FALSE>>=
u1 <- runif(500)
u2 <- runif(500)
x1 <- outer(u1, u2, function(x, y)
            sqrt((-2 * log(x))) * cos(2 * pi * y))
x2 <- outer(u1, u2, function(x, y)
            sqrt((-2 * log(x))) * sin(2 * pi * y))
hist(x1, prob = TRUE)
curve(dnorm(x), add = TRUE)
@
    \end{enumerate}
    La \autoref{fig:simulation:boxmuller} illustre d'une autre façon que la
    transformation de Box--Muller fonctionne bel et bien. Dans le
    graphique de gauche, on a plusieurs couples de points $(u_1, u_2)$
    où chaque composante provient d'une distribution uniforme sur
    l'intervalle $(0, 1)$.

    Chacun de ces points a été transformé en un point $(x_1, x_2)$
    selon la transformation de Box--Muller, puis placé dans le
    graphique de droite. On a superposé le nuage de points ainsi
    obtenu aux lignes de niveau d'une distribution normale bivariée
    (avec paramètre $\rho = 0$). On observe que la répartition et la
    densité du nuage de points correspond effectivement aux lignes de
    niveau.
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
u1 <- runif(1000)
u2 <- runif(1000)
x1 <- sqrt(-2 * log(u1)) * cos(2 * pi * u2)
x2 <- sqrt(-2 * log(u1)) * sin(2 * pi * u2)

col <- rgb(0.67, 0.85, 0.90, alpha = 0.4) # "lightblue" semi-transparent
par(mfrow = c(1, 2))

plot(u1, u2, pch = 19, col = col)

f <- function(x, y) dnorm(x) * dnorm(y)
x <- seq(-3, 3, length = 100)
z <- outer(x, x, f)
contour(x, x, z, xlim = c(-3, 3), ylim = c(-3, 3),
        nlevels = 15, method = "edge", xlab = "x1", ylab = "x2")
points(x1, x2, pch = 19, col = col)
@
      \caption{Démonstration graphique du fonctionnement de la
        transformation de Box--Muller}
      \label{fig:simulation:boxmuller}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  La distribution de Laplace, ou double exponentielle, est définie
  comme la différence entre deux distributions exponentielles
  identiques et indépendantes. Sa fonction de densité de probabilité
  est
  \begin{displaymath}
    f(x) = \frac{\lambda}{2}\, e^{-\lambda |x|}, \quad
    -\infty < x < \infty.
  \end{displaymath}
  Proposer une ou plusieurs façons de simuler des nombres issus de
  cette distribution.
  \begin{sol}
    Deux suggestions:
    \begin{enumerate}[1.]
    \item Simuler deux nombres indépendants $x_1$ et $x_2$ d'une loi
      exponentielle de paramètre $\lambda$ et poser $y = x_1 - x_2$.
    \item La fonction de répartition de la distribution de Laplace est
      \begin{align*}
        F_{Y}(y)
        &=
        \begin{cases}
          \frac{1}{2}e^{\lambda x}, & x < 0 \\
          1-\frac{1}{2}e^{-\lambda x}, & x \geq 0,
        \end{cases} \\
        \intertext{d'où}
        F_{Y}^{-1}(u)
        &=
        \begin{cases}
          \frac{1}{\lambda} \ln (2u) & u < 0,5 \\
          \frac{-1}{\lambda} \ln (2(1-u) ) & u \geq 0,5.
        \end{cases}
      \end{align*}
      On peut donc utiliser la méthode inverse.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  En ouverture de chapitre, on mentionne qu'une façon de simuler des
  nombres issus d'une loi géométrique consiste à extraire la partie
  entière de nombres aléatoires provenant d'une loi exponentielle.

  Démontrer que si la loi de la variable aléatoire $X$ est une
  exponentielle, alors la loi de $\lfloor X \rfloor$ est une
  géométrique. Déterminer le paramètre de la loi géométrique en
  fonction du paramètre de la loi exponentielle.
  \begin{rep}
    $p = 1 - e^{-\lambda}$
  \end{rep}
  \begin{sol}
    Soit $X \sim \text{Exponentielle}(\lambda)$ et
    $K = \lfloor X \rfloor$. On a donc:
    \begin{align*}
      \Pr[K = 0]
      &= \Pr[\lfloor X \rfloor = 0] \\
      &= \Pr[0 \leq X < 1] \\
      &= F_X(1) \\
      &= 1 - e^{-\lambda}, \displaybreak[0] \\
      \Pr[K = 1]
      &= \Pr[1 \leq X < 2]\\
      &= F_X(2) - F_X(1)\\
      &= (1 - e^{-2 \lambda}) - (1 - e^{-\lambda}) \\
      &= (e^{-\lambda} - e^{-2\lambda}) \\
      &= (1 - e^{-\lambda}) e^{-\lambda}, \displaybreak[0] \\
      \intertext{soit, de manière générale,}
      \Pr[K = k]
      &= \Pr[k \leq X < k+1]\\
      &= (1 - e^{-\lambda})(e^{-\lambda})^k,
        \quad k = 0, 1, 2, \dots
    \end{align*}
    La forme de cette fonction de masse de probabilité est celle
    d'une loi géométrique de paramètre $p = 1 - e^{-\lambda}$.
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:gamma}
  Faire la mise en oeuvre informatique (dans le langage de votre
  choix) de l'algorithme de simulation suivant. Il s'agit d'un
  algorithme pour simuler des observations d'une loi Gamma$(\alpha,
  1)$, où $\alpha > 1$.
  \begin{enumerate}[1.]
  \item Générer $u_1$ et $u_2$ indépendemment d'une loi $U(0, 1)$ et
    poser
    \begin{displaymath}
      v = \frac{(\alpha - \frac{1}{6\alpha}) u_1}{(\alpha - 1) u_2}.
    \end{displaymath}
  \item Si
    \begin{displaymath}
      \frac{2 (u_2 - 1)}{\alpha - 1} + v + \frac{1}{v} \leq 2,
    \end{displaymath}
    alors retourner le nombre $x = (\alpha - 1) v$. Sinon, si
    \begin{displaymath}
      \frac{2 \log u_2}{\alpha - 1} - \log v + v \leq 1,
    \end{displaymath}
    alors retourner le nombre $x = (\alpha - 1) v$.
  \item Répéter au besoin la procédure depuis l'étape 1.
  \end{enumerate}
  Faire les vérifications empiriques usuelles de la validité de
  l'algorithme.
  \begin{sol}
    Voir la fonction R de la \autoref{fig:simulation:gamma}. On vérifie
    graphiquement la validité de l'algorithme:
<<echo=TRUE, eval=FALSE>>=
hist(rgamma2(1000, 5), prob = TRUE)
curve(dgamma(x, 5, 1), add = TRUE)
@
    \begin{figure}
      \centering
      \begin{framed}
\begin{lstlisting}
rgamma2 <- function(nsim, alpha)
{
    x <- numeric(nsim)
    i <- 0
    while (i < nsim)
    {
        u <- runif(2)
        v <- (alpha - 1/(6 * alpha)) * u[1] /
               ((alpha - 1) * u[2])

        if ((2 * (u[2] - 1)/(alpha - 1) +
               v + 1/v <= 2) |
            (2 * log(u[2])/(alpha - 1) -
               log(v) + v <= 1))
            x[i <- i + 1] <- (alpha - 1) * v
    }
    x
}
\end{lstlisting}
      \end{framed}
      \caption{Fonction de simulation d'une distribution
        Gamma$(\alpha, 1)$, $\alpha > 1$}
      \label{fig:simulation:gamma}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  En utilisant le résultat de l'exercice précédent, quelle procédure
  pourrait-on suivre pour simuler des nombres d'une loi Gamma$(\alpha,
  \lambda)$ où $\alpha > 1$?
  \begin{sol}
    Deux suggestions.
    \begin{enumerate}[1.]
    \item Si $X \sim \text{Gamma}(\alpha, 1)$, alors $Y = X/\lambda
      \sim \text{Gamma}(\alpha, \lambda)$. On peut donc générer un
      nombre $x$ d'une loi Gamma$(\alpha, 1)$ avec l'algorithme de
      l'\autoref{ex:simulation:gamma}, puis poser $y =
      x/\lambda$.
    \item Si $\alpha$ est entier, on peut générer $\alpha$ nombres
      (indépendants) $x_1, \dots, x_\alpha$ d'une distribution
      Exponentielle$(\lambda)$ et poser $y = \sum_{i=1}^\alpha x_i$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Démontrer que si $X|\Theta \sim \text{Exponentielle}(\Theta)$
    et $\Theta \sim \text{Gamma}(\alpha, \lambda)$, alors $X \sim
    \text{Pareto}(\alpha, \lambda)$. La fonction de densité de
    probabilité d'une loi de Pareto est
    \begin{displaymath}
      f(x) = \frac{\alpha \lambda^\alpha}{(x + \lambda)^{\alpha + 1}},
      \quad x > 0.
    \end{displaymath}
  \item Utiliser le résultat ci-dessus pour proposer un algorithme de
    simulation de nombres issus d'une loi de Pareto. Faire la mise en
    oeuvre informatique de cet algorithme et les vérifications d'usage
    de sa validité.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On a $X|\Theta \sim \text{Exponentielle}(\Theta)$ et $\Theta
      \sim \text{Gamma}(\alpha, \lambda)$. Par la loi des probabilités
      totales,
      \begin{align*}
        f_{X}(x)
        &= \int_0^\infty f(x|\theta) u(\theta)\, d\theta  \\
        &= \frac{\lambda^\alpha}{\Gamma(\alpha)} \int_0^\infty
        \theta^{\alpha + 1 - 1} e^{-(\lambda + x) \theta}\, d\theta
          \displaybreak[0]\\
        &= \frac{\lambda^\alpha}{\Gamma(\alpha)}
        \frac{\Gamma(\alpha + 1)}{(\lambda + x)^{\alpha +1}} \\
        &= \frac{\alpha \lambda^\alpha}{(\lambda + x)^{\alpha +1}}.
      \end{align*}
    \item Pour générer un nombre d'une distribution de Pareto de
      paramètres $\alpha$ et $\lambda$ avec le résultat en a), on
      génère d'abord un nombre $\theta$ d'une distribution gamma de
      mêmes paramètres, puis on génère un nombre $x$ d'une
      distribution exponentielle de paramètre $\theta$. En R:
<<echo=TRUE, eval=FALSE>>=
rexp(1, rgamma(1, alpha, lambda))
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  La fonction de densité de probabilité de la loi de
  Pareto translatée est
  \begin{displaymath}
    f(x) = \frac{\alpha \lambda^\alpha}{x^{\alpha + 1}}, \quad x > \lambda.
  \end{displaymath}
  Simuler trois valeurs d'une telle distribution avec $\alpha = 2$ et
  $\lambda = \nombre{1000}$ à l'aide de la méthode de l'inverse et du
  générateur congruentiel linéaire suivant:
  \begin{displaymath}
    x_n = (65 x_{n-1} + 1) \bmod \nombre{2048}.
  \end{displaymath}
  Utiliser une amorce de $12$.
  \begin{rep}
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.3813))}}$,
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.7881))}}$,
    $\nombre{\Sexpr{round(1000/sqrt(1 - 0.2261))}}$
  \end{rep}
  \begin{sol}
    La fonction de répartition de la Pareto translatée$(\alpha,
    \lambda)$ est
    \begin{align*}
      F(x)
      &= \int_\lambda^x
      \frac{\alpha \lambda^\alpha}{y^{\alpha + 1}}\, dy \\
      &=
      \begin{cases}
        0, & x \leq \lambda \\
        1 - \left( \frac{\lambda}{x} \right)^\alpha, & x > \lambda
      \end{cases} \\
      \intertext{et son inverse est}
      F^{-1}(y)
      &=
      \begin{cases}
        \lambda, & y = 0 \\
        \frac{\lambda}{(1 - y)^{1/\alpha}}, & 0 < y < 1.
      \end{cases}
    \end{align*}
    Par conséquent, si $U \sim U(0, 1)$, alors
    \begin{displaymath}
      X = \frac{\lambda}{(1 - U)^{1/\alpha}} \sim
      \text{Pareto translatée}(\alpha, \lambda).
    \end{displaymath}
    Les trois premières valeurs retournées par le générateur
    \begin{displaymath}
      x_n = (65 x_{n-1} + 1) \bmod \nombre{2048}
    \end{displaymath}
    avec une amorce de $12$ sont $781$, $\nombre{1614}$ et $463$. En divisant
    ces nombres par $\nombre{2048}$, on obtient des nombres dans
    l'intervalle $(0, 1)$:
    \begin{displaymath}
      0,3813 \quad 0,7881 \quad 0,2261.
    \end{displaymath}
    Finalement, les observations de la Pareto$(2, \nombre{1000})$ sont
<<echo=TRUE>>=
1000/sqrt(1 - c(0.3813, 0.7881, 0.2261))
@
    \emph{Remarque:} puisque $1 - U \sim U(0, 1)$ si $U \sim U(0, 1)$,
    les nombres issus de la transformation $\lambda (1 -
    U)^{-1/\alpha}$ seraient tout aussi distribués selon une Pareto
    translatée. Les réponses seraient toutefois différentes.
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:disque}
  Soit $U_1$ et $U_2$ deux variables aléatoires indépendantes
  uniformément distribuées sur l'intervalle $(0, 1)$ et soit la
  transformation
  \begin{align*}
    X_1 &= \sqrt{U_1} \cos(2 \pi U_2) \\
    X_2 &= \sqrt{U_1} \sin(2 \pi U_2).
  \end{align*}
  Démontrer que la distribution conjointe de $X_1$ et $X_2$ est
  uniforme sur le disque de rayon de $1$ centré en $(x_1, x_2) = (0,
  0)$. À quoi ce résultat peut-il servir?
  \begin{sol}
    On a la transformation
    \begin{displaymath}
      \begin{split}
        X_1 &= \sqrt{U_1} \cos(2 \pi U_2) \\
        X_2 &= \sqrt{U_1} \sin(2 \pi U_2)
      \end{split}
      \quad \Leftrightarrow \quad
      \begin{split}
        U_1 &= X_1^2 + X_2^2 \\
        U_2 &= \frac{1}{2\pi} \arctan \frac{X_2}{X_1}.
      \end{split}
    \end{displaymath}
    Cette transformation associe les points de l'espace $\{(u_1, u_2):
    0 < u_1 < 1, 0 < u_2 < 1\}$ à ceux de l'espace $\{(x_1, x_2):
    x_1^2 + x_2^2 < 1 \backslash (0, 0)\}$. Cela se vérifie aisément
    en examinant les limites de l'espace de départ:
    \begin{align*}
      u_1 &> 0 &\Rightarrow&& x_1^2 + x_2^2 &> 0 \\
      u_1 &< 1 &\Rightarrow&& x_1^2 + x_2^2 &< 1 \\
      u_2 &> 0 &\Rightarrow&& \frac{x_2}{x_1} &> 0 \\
      u_2 &< 1 &\Rightarrow&& \frac{x_2}{x_1} &< 0.
    \end{align*}
    Les troisième et quatrième inégalités définissent les quadrants I
    et III, puis II et IV de $\R^2$, respectivement. On remarque
    également que le point $(0, 0)$, qui a probabilité zéro, ne se
    trouve pas dans l'espace image.

    Le Jacobien de la transformation est
    \begin{align*}
      J
      &=
      \begin{vmatrix}
        \dfrac{\partial u_1}{\partial x_1} &
        \dfrac{\partial u_1}{\partial x_2} \\[8pt]
        \dfrac{\partial u_2}{\partial x_1} &
        \dfrac{\partial u_2}{\partial x_2}
      \end{vmatrix} \\
      &=
      \begin{vmatrix}
        2 x_1 &
        2 x_2 \\[6pt]
        -\dfrac{1}{2\pi} \dfrac{x_2}{x_1^2 + x_2^2} &
        \dfrac{1}{2\pi} \dfrac{x_1}{x_1^2 + x_2^2},
      \end{vmatrix} \\
      &=
      \frac{1}{\pi}.
    \end{align*}
    La fonction de densité de probabilité conjointe de $X_1$ et $X_2$
    est donc
    \begin{align*}
      f_{X_1,X_2}(x_1, x_2)
      &= f_{U_1, U_2}(u_1, u_2) |J| \\
      &= \frac{1}{\pi}, \quad -1 < x_1 < 1, -\sqrt{1 - x_1^2} < x_2 <
      \sqrt{1 - x_1^2},
    \end{align*}
    soit une distribution uniforme sur le disque unité.

    Le résultat peut évidemment servir à simuler des points
    uniformément répartis sur un disque de rayon $1$ centré en $(0,
    0)$. La \autoref{fig:simulation:disque2} illustre d'ailleurs cette
    transformation. Les points $(u_1, u_2)$ dans le graphique de gauche
    sont tirés aléatoirement sur le carré $(0, 1) \times (0, 1)$. Le
    graphique de droite montre que suite à la tranformation ci-dessus,
    on obtient des points $(x_1, x_2)$ distribués uniformément sur un
    disque de rayon $1$ centré en $(0, 0)$.
    \begin{figure}
      \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
col <- rgb(0.67, 0.85, 0.90, alpha = 0.4) # "lightblue" semi-transparent
par(mfrow = c(1, 2))
u1 <- runif(1000)
u2 <- runif(1000)
x1 <- sqrt(u1) * cos(2 * pi * u2)
x2 <- sqrt(u1) * sin(2 * pi * u2)
plot(u1, u2, pch = 19, col = col)
plot(x1, x2, pch = 19, col = col)
@
      \caption{Démonstration graphique du fonctionnement de la
        transformation de l'\autoref{ex:simulation:disque}}
      \label{fig:simulation:disque2}
    \end{figure}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:gamma-beta}
  \begin{enumerate}
  \item Soit $Y_1 \sim \text{Gamma}(\alpha, 1)$ et $Y_2 \sim
    \text{Gamma}(\beta, 1)$ deux variables aléatoires
    indépendantes. Démontrer que
    \begin{displaymath}
      X = \frac{Y_1}{Y_1 + Y_2} \sim \text{Bêta}(\alpha, \lambda).
    \end{displaymath}
  \item Utiliser le résultat en a) pour proposer un algorithme de
    simulation d'observations d'une loi Bêta$(\alpha, \lambda)$.
  \item Faire la mise en oeuvre informatique de l'algorithme en b)
    ainsi que les vérifications d'usage.
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item On a
      \begin{align*}
        f_{Y_1}(y_1)
        &= \frac{1}{\Gamma(\alpha)}\, y_1^{\alpha - 1} e^{-y_1}, \quad
        y_1 > 0, \\
        f_{Y_2}(y_2)
        &= \frac{1}{\Gamma(\beta)}\, y_2^{\beta - 1} e^{-y_2}, \quad
        y_2 > 0 \\
        \intertext{et}
        f_{Y_1, Y_2}(y_1, y_2)
        &= \frac{1}{\Gamma(\alpha) \Gamma(\beta)}\,
        y_1^{\alpha - 1} y_2^{\beta - 1} e^{-(y_1 + y_2)}, \quad
        y_1 > 0, y_2 > 0.
      \end{align*}
      Soit $X_1 = Y_1/(Y_1 + Y_2)$ et $X_2 = Y_1 + Y_2$ (le choix de
      $X_2$ étant justifié par l'exposant de la distribution conjointe
      de $Y_1$ et $Y_2$). On cherche la distribution conjointe de
      $X_1$ et $X_2$, $f_{X_1, X_2}(x_1, x_2)$. On a la transformation
      \begin{displaymath}
        \begin{split}
          x_1 &= \frac{y_1}{y_1 + y_2} \\
          x_2 &= y_1 + y_2
        \end{split}
        \quad \Leftrightarrow \quad
        \begin{split}
          y_1 &= x_1 x_2 \\
          y_2 &= x_2 - x_1 x_2.
        \end{split}
      \end{displaymath}
      Cette transformation associe de manière évidente les points de
      l'espace $\{(y_1, y_2): y_1 > 0, y_2 > 0\}$ à ceux de l'espace
      $\{(x_1, x_2): 0 < x_1 < 1, x_2 > 0\}$.

      Le Jacobien de la transformation est
      \begin{align*}
        J
        &=
        \begin{vmatrix}
          \dfrac{\partial y_1}{\partial x_1} &
          \dfrac{\partial y_1}{\partial x_2} \\[8pt]
          \dfrac{\partial y_2}{\partial x_1} &
          \dfrac{\partial y_2}{\partial x_2}
        \end{vmatrix} \\
        &=
        \begin{vmatrix}
          x_2 & x_1 \\
          -x_2 & 1 - x_1
        \end{vmatrix} \\
        &=
        x_2.
      \end{align*}
      La fonction de densité de probabilité conjointe de $X_1$ et $X_2$
      est donc
      \begin{align*}
        f_{X_1,X_2}&(x_1, x_2)
         = f_{Y_1, Y_2}(y_1, y_2) |J| \\
        &= \frac{1}{\Gamma(\alpha) \Gamma(\beta)}\,
        x_1^{\alpha - 1} (1 - x_1)^{\beta - 1}
        x_2^{\alpha + \beta - 1} e^{-x_2} \\
        &=
        \left[
          \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)}\,
          x_1^{\alpha - 1} (1 - x_1)^{\beta - 1}
        \right]
        \left[
          \frac{1}{\Gamma(\alpha + \beta)}\,
          x_2^{\alpha + \beta - 1} e^{-x_2}
        \right],
      \end{align*}
      pour $0 < x_1 < 1$, $x_2 > 0$, d'où $X_1$ et $X_2$ sont
      indépendantes, $X_1 \sim \text{Bêta}(\alpha, \beta)$ et $X_2
      \sim \text{Gamma}(\alpha + \beta)$ (un résultat connu).
    \item La conversion du résultat en un algorithme est très simple:
      \begin{quote}
        \begin{enumerate}[1.]
        \item Générer $y_1$ d'une distribution Gamma$(\alpha, 1)$.
        \item Générer $y_2$ d'une distribution Gamma$(\beta, 1)$.
        \item Poser $x = y_1/(y_1 + y_2)$.
        \end{enumerate}
      \end{quote}
      Cet algorithme suppose évidemment qu'une source de nombres
      provenant d'une loi gamma est disponible.

      La \autoref{fig:simulation:gamma-beta} illustre le fonctionnement de
      cette transformation. Dans le graphique de gauche, on a un nuage
      de points $(y_1, y_2)$ tirés indépendemment de deux
      distributions gamma de paramètre d'échelle égal à 1. On a
      superposé ce nuage de points aux courbes de niveaux de la
      distribution conjointe des deux lois gamma.

      Dans le graphique de droite, on a placé en abscisse les points
      $x = y_1/(y_1 + y_2)$ résultant de la transformation. On voit
      que la répartition et la densité de ces points correspond à la
      densité de la loi bêta également représentée sur le graphique.
      \begin{figure}
        \centering
<<echo=FALSE, fig=TRUE, width=10, height=5>>=
col <- rgb(0.67, 0.85, 0.90, alpha = 0.4) # "lightblue" semi-transparent
par(mfrow = c(1, 2))
f <- function(x, y) dgamma(x, 2) * dgamma(y, 3)
y <- seq(0, 8, length = 100)
z <- outer(y, y, f)
contour(y, y, z, xlim = c(0, 8), ylim = c(0, 8),
        nlevels = 15, method = "edge",
        xlab = expression(y[1]), ylab = expression(y[2]))

y1 <- rgamma(100, 2)
y2 <- rgamma(100, 3)
points(y1, y2, pch = 19, col = col)

curve(dbeta(x, 2, 3), xlim = c(0, 1), lwd = 2)
points(y1/(y1 + y2), rep(0, length(y1)), pch = 19, col = col)
@
        \caption{Démonstration graphique du fonctionnement de la
          transformation de l'\autoref{ex:simulation:gamma-beta}}
        \label{fig:simulation:gamma-beta}
      \end{figure}
    \item En R:
<<echo=TRUE,eval=FALSE>>=
(y <- rgamma(1, alpha, 1))/(y + rgamma(1, beta, 1))
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Dans la méthode d'acceptation-rejet, un nombre $y$ tiré d'une
    variable aléatoire $Y$ avec fonction de densité de probabilité
    $g_Y(\cdot)$ est accepté comme réalisation d'une variable
    aléatoire $X$ avec fonction de densité de probabilité $f_X(\cdot)$ si
    \begin{displaymath}
      U \leq \frac{f_X(y)}{c g_Y(y)},
    \end{displaymath}
    où $U \sim U(0, 1)$. Calculer la probabilité d'accepter une valeur
    lors de toute itération de la méthode d'acceptation-rejet,
    c'est-à-dire
    \begin{displaymath}
      \Pr \left[ U \leq \frac{f_X(Y)}{c g_Y(Y)} \right].
    \end{displaymath}
    \emph{Astuce}: utiliser la loi des probabilités totales en
    conditionnant sur $Y = y$.
  \item Déterminer la distribution du nombre d'essais avant d'accepter
    un nombre $y$ dans la méthode d'acceptation-rejet.
  \item Déterminer le nombre moyen d'essais avant d'accepter un nombre
    $y$ dans la méthode d'acceptation-rejet.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $1/c$
    \item Géométrique$(1/c)$ commençant à $1$
    \item $c$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On a
      \begin{align*}
        \Pr \left[ U \leq \frac{f_X(y)}{c g_Y(y)} \right]
        &= \int_{-\infty}^\infty
        \Pr \left[ U \leq \frac{f_X(y)}{c g_Y(y)}\biggr\rvert Y = y \right] %|
        g_Y(y)\, dy \\
        &= \int_{-\infty}^\infty
        \frac{f_X(y)}{c g_Y(y)}\, g_Y(y)\, dy \displaybreak[0] \\
        &= \frac{1}{c} \int_{-\infty}^\infty f_X(y)\, dy \\
        &= \frac{1}{c}.
      \end{align*}
    \item Les essais étant indépendants, la distribution du nombre
      d'essais avant d'avoir un succès (accepter un nombre $y$) est
      géométrique de paramètre $1/c$, c'est-à-dire que
      \begin{displaymath}
        \Pr[Z = z] =
        \left( \frac{1}{c} \right)
        \left( 1 - \frac{1}{c} \right)^{z - 1}, \quad z = 1, 2, \dots,
      \end{displaymath}
      où $Z$ représente le nombre d'essais avant d'accepter un nombre.
    \item On a $\esp{Z} = 1/(1/c) = c$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:mode}
  Soit $X$ une variable aléatoire continue définie sur l'intervalle
  $(a, b)$, où $a$ et $b$ sont des nombres réels. Pour simuler des
  observations de cette variable aléatoire par la méthode
  d'acceptation-rejet, on peut toujours inscrire la fonction de
  densité de probabilité de $X$ dans un rectangle de hauteur $M$, ou
  $M$ est la valeur de la densité au mode de $X$.
  \begin{enumerate}
  \item Énoncer l'algorithme d'acceptation-rejet découlant d'une telle
    procédure.
  \item Calculer l'\emph{efficacité} de l'algorithme en a), soit la
    probabilité d'accepter une valeur lors d'une itération de
    l'algorithme.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
      \stepcounter{enumi}
    \item $1/(M (b - a))$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On pose
      \begin{displaymath}
        c g_Y(x) = M, \quad a < x < b,
      \end{displaymath}
      soit $Y \sim U(a, b)$ et $c = M (b - a)$. L'algorithme
      d'acceptation-rejet est donc le suivant:
      \begin{enumerate}[1.]
      \item Simuler deux nombres indépendants $u_1$ et $u_2$ d'une
        loi $U(0, 1)$.
      \item Poser $y = a + (b - a) u_1$.
      \item Si $u_2 \leq f_X(y)/M$, poser $x = y$. Sinon, retourner
        à l'étape 1.
      \end{enumerate}
    \item L'efficacité est
      \begin{displaymath}
        \frac{1}{c} = \frac{1}{M (b - a)}.
      \end{displaymath}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:beta}
  Considérer le problème de simulation d'observations d'une loi
  Bêta$(3, 2)$ à l'aide de la méthode d'acceptation-rejet.
  \begin{enumerate}
  \item Calculer l'efficacité de l'algorithme développé à
    l'\autoref{ex:simulation:mode} et à
    l'\autoref{exemple:simulation:beta:1} pour le cas présent.
  \item Calculer l'efficacité de l'algorithme développé dans
    l'\autoref{exemple:simulation:beta:2}, où l'on a déterminé que
    \begin{displaymath}
      f_{X}(x) \leq
      \begin{cases}
        3x, & 0 < x < 0,8 \\
        12 - 12 x, & 0,8 \leq x < 1.
      \end{cases}
    \end{displaymath}
  \item Faire la mise en oeuvre informatique de l'algorithme le plus
    efficace entre celui de la partie a) et celui de la partie b).
    Vérifier la fonction en superposant l'histogramme d'un grand
    échantillon obtenu avec cette fonction et la vraie fonction de
    densité de la loi bêta.
  \end{enumerate}
  \begin{rep}
    \begin{inparaenum}
    \item $9/16$
    \item $4/5$
    \end{inparaenum}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On démontre facilement que le mode $M$ d'une distribution
      bêta de paramètres $\alpha$ et $\beta$ se trouve en
      \begin{displaymath}
        x = \frac{\alpha - 1}{\alpha + \beta - 2}.
      \end{displaymath}
      Par conséquent, l'efficacité de l'algorithme d'acceptation-rejet
      décrit à l'\autoref{ex:simulation:mode} et consistant à
      borner la densité par un rectangle de hauteur $M$ est
      \begin{align*}
        \frac{1}{M}
        &= \frac{1}{f((\alpha - 1)/(\alpha + \beta - 2))} \\
        &= \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}
        \left(
          \frac{\alpha - 1}{\alpha + \beta - 2}
        \right)^{1 - \alpha}
        \left(
          \frac{\beta - 1}{\alpha + \beta - 2}
        \right)^{1 - \beta}.
      \end{align*}
      Avec $\alpha = 3$ et $\beta = 2$, on obtient une efficacité de
      $9/16$.
    \item On a trouvé $c = 1,2$ dans
      l'\autoref{exemple:simulation:beta:2}, d'où une efficacité de
      $1/c = 5/6$. Cet algorithme est évidemment plus efficace puisque
      la surface de l'enveloppe de la densité bêta est nettement plus
      petite.
    \item On utilise l'algorithme développé à
      l'\autoref{exemple:simulation:beta:2}. Une première mise en
      œuvre de l'algorithme en R est fournie dans le code
      informatique de la \autoref{sec:simulation:code}. La
      \autoref{fig:simulation:rbeta.ar2} en propose une autre. On
      propose aussi une mise en œuvre VBA à la \autoref{fig:simulation:betasim}.
      \begin{figure}[t]
        \centering
        \begin{framed}
\begin{lstlisting}
rbeta.ar2 <- function(n)
{
    g <- function(x)
        ifelse(x < 0.8, 2.5 * x, 10 - 10 * x)
    Ginv <- function(y)
        ifelse(y < 0.8, sqrt(0.8 * y),
               1 - sqrt(0.2 - 0.2 * y))
    x <- numeric(n)
    i <- 0
    while(i < n)
    {
        y <- Ginv(runif(1))
        if(1.2 * g(y) * runif(1) <=
           dbeta(y, shape1 = 3, shape2 = 2))
            x[i <- i + 1] <- y
    }
    x
}
\end{lstlisting}
        \end{framed}
        \caption{Code R de la fonction \code{rbeta.ar2}}
        \label{fig:simulation:rbeta.ar2}
      \end{figure}
      \begin{figure}
        \centering
        \begin{framed}
\begin{lstlisting}
Private Function sqrt(x)
    sqrt = x ^ 0.5
End Function

Private Function g(x As Double)
    DensiteTriangle = IIf(x < 0.8, 2.5 * x,
                          10 - 10 * x)
End Function

Private Function Ginv(u As Double)
    InverseTriangle = IIf(u < 0.8, sqrt(0.8 * u),
                          1 - sqrt(0.2 - 0.2 * u))
End Function

Private Function dbeta(x As Double, shape1 As Double,
                       shape2 As Double)
    Dim cte As Double
    With WorksheetFunction
        cte = Exp(.GammaLn(shape1 + shape2) -
                  .GammaLn(shape1) -
                  .GammaLn(shape2))
        dbeta = cte * x ^ (shape1 - 1) *
                (1 - x) ^ (shape2 - 1)
    End With
End Function

Function betasim()
    Dim u1 As Double, u2 As Double, y As Double

    Do
        u1 = Rnd
        u2 = Rnd
        y = Ginv(u1)
    Loop Until u2 <= dbeta(y, 3, 2) / (1.2 * g(y))

    SimuleBeta = y
End Function
\end{lstlisting}
        \end{framed}
        \caption{Code VBA de la fonction \code{betasim}}
        \label{fig:simulation:betasim}
      \end{figure}
      On peut vérifier l'exactitude la fonction \code{rbeta.ar2} avec
<<echo=TRUE, eval=FALSE>>=
x <- rbeta.ar2(10000)
hist(x, prob = TRUE)
curve(dbeta(x, 3, 2), add = TRUE)
@
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \label{ex:simulation:rejet}
  La fonction R de la \autoref{fig:simulation:fonction} permet de
  simuler des observations de la distribution Bêta$(\alpha, \beta)$.
    \begin{figure}[t]
      \begin{framed}
\begin{lstlisting}
simul <- function(n, alpha, beta)
{
    xmax <- (alpha - 1)/(alpha + beta - 2)
    M <- dbeta(xmax, alpha, beta)
    x <- numeric(n)
    i <- 0
    repeat
    {
        u <- runif(1)
        if (M * runif(1) <= dbeta(u, alpha, beta))
            x[i <- i + 1] <- u
        if (i == n)
            break
    }
    x
}
\end{lstlisting}
      \end{framed}
      \caption{Fonction de simulation d'une loi Bêta$(\alpha, \beta)$
        pour l'\autoref{ex:simulation:rejet}}
      \label{fig:simulation:fonction}
    \end{figure}
  \begin{enumerate}
  \item Identifier le type d'algorithme utilisé dans cette fonction.
  \item On vous donne également les valeurs suivantes, obtenues dans
    R:
<<echo=FALSE>>=
op <- options(width = 50, digits = 2)
simul <- function(n, alpha, beta)
{
    ymax <- dbeta((alpha-1)/(alpha + beta - 2), alpha, beta)
    x <- numeric(n)
    i <- 1
    repeat
    {
        u <- runif(1)
        if (ymax * runif(1) <= dbeta(u, alpha, beta))
        {
            x[i] <- u
            i <- i + 1
        }
        if (i > n)
            break
    }
    x
}
@
<<echo=TRUE>>=
set.seed(12345)
runif(10)
@
    Évaluer le résultat des expressions suivantes:
<<echo=TRUE, eval=FALSE>>=
set.seed(12345)
simul(2, alpha = 2, beta = 3)
@
  \end{enumerate}
  \begin{rep}
<<echo=FALSE>>=
set.seed(12345)
x <- round(simul(2, alpha = 2, beta = 3), 2)
options(op)
@
    \begin{enumerate}[a)]
      \stepcounter{enumii}
    \item $\Sexpr{x[1]}$, $\Sexpr{x[2]}$
    \end{enumerate}
  \end{rep}
  \begin{sol}
    \begin{enumerate}
    \item On reconnaît l'algorithme d'acceptation-rejet de
      l'\autoref{ex:simulation:mode}.
    \item On doit simuler deux observations d'une loi Bêta$(2, 3)$
      dont la fonction de densité de probabilité est
      \begin{displaymath}
        f(x) = 12 x (1 - x)^2, \quad 0 < x < 1.
      \end{displaymath}
      Le mode de cette densité se trouve en $x = 1/3$ (voir la
      solution de l'\autoref{ex:simulation:beta}) et la valeur de
      ce mode est $M = f(1/3) = 16/9$. Pour obtenir le résultat de
      l'appel de la fonction \code{simul}, il faut s'assurer
      d'utiliser les nombres uniformes dans le bon ordre. Quatre
      itérations de la boucle \code{repeat} seront nécessaires;
      voici leurs résultas.
      \begin{enumerate}[1.]
      \item On a $u = 0,72$, puis $(16/9) (0,88) > f(0,72)$, donc $u$
        est rejeté.
      \item On a $u = 0,76$, puis $(16/9) (0,89) > f(0,76)$, donc $u$
        est rejeté.
      \item On a $u = 0,46$, puis $(16/9) (0,17) < f(0,46)$, donc $u$
        est accepté: $x_1 = 0,46$.
      \item On a $u = 0,33$, puis $(16/9) (0,51) < f(0,33)$, donc $u$
        est accepté: $x_2 = 0,33$.
      \end{enumerate}
      Le résultat est donc le vecteur $\mat{x} = (0,46, 0,33)$.
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  \begin{enumerate}
  \item Démontrer que, si $0 < \alpha < 1$,
    \begin{displaymath}
      x^{\alpha - 1} e^{-x} \leq
      \begin{cases}
        x^{\alpha - 1}, & 0 \leq x \leq 1 \\
        e^{-x},        & x > 1.
      \end{cases}
    \end{displaymath}
  \item Développer un algorithme d'acceptation-rejet pour simuler des
    observations d'une loi Gamma$(\alpha, 1)$, $0 < \alpha < 1$ à
    partir du résultat en a).
  \end{enumerate}
  \begin{sol}
    \begin{enumerate}
    \item Si $0 \leq x \leq 1$, $e^{-1} < e^{-x} < 1$, d'où $x^{\alpha
        - 1} e^{-x} \leq x^{\alpha - 1}$. De même, puisque $0 < \alpha
      < 1$, $x^{\alpha - 1} < 1$ pour $x > 1$, d'où  $x^{\alpha - 1}
      e^{-x} \leq e^{-x}$ pour $x > 1$.
    \item On veut borner la densité $f_X(x) = x^{\alpha - 1}
      e^{-x}/\Gamma(\alpha)$, $x > 0$ et $0 < \alpha < 1$. Du résultat
      en a), on a
      \begin{displaymath}
        f_X(x) \leq
        \begin{cases}
          x^{\alpha - 1}/\Gamma(\alpha), & 0 \leq x \leq 1 \\
          e^{-x}/\Gamma(\alpha),        & x > 1.
        \end{cases}
      \end{displaymath}
      Posons
      \begin{displaymath}
        c g_Y(x) =
        \begin{cases}
          x^{\alpha - 1}/\Gamma(\alpha), & 0 \leq x \leq 1 \\
          e^{-x}/\Gamma(\alpha),        & x > 1.
        \end{cases}
      \end{displaymath}
      L'aire totale sous la fonction $c g_Y(x)$ est
      \begin{displaymath}
        \int_0^1 \frac{x^{\alpha - 1}}{\Gamma(\alpha)}\, dx +
        \int_1^\infty \frac{e^{-x}}{\Gamma(\alpha)}\, dx =
        \frac{1}{\Gamma(\alpha)}
        \left(
          \frac{1}{\alpha} + \frac{1}{e}
        \right),
      \end{displaymath}
      d'où
      \begin{align*}
        g_Y(x)
        &=
        \begin{cases}
          \dfrac{x^{\alpha - 1}}{(1/\alpha) + (1/e)}, & 0 \leq x \leq 1 \\
          \dfrac{e^{-x}}{(1/\alpha) + (1/e)}, & x > 1,
        \end{cases} \\
        G_Y(x)
        &=
        \begin{cases}
          \dfrac{e}{\alpha + e}\, x^\alpha, & 0 \leq x \leq 1 \\
          1 - \dfrac{e^{-x}}{(1/\alpha) + (1/e)}, & x > 1,
        \end{cases} \\
        \intertext{et}
        G_Y^{-1}(x)
        &=
        \begin{cases}
          \left( \dfrac{\alpha + e}{e}\, x \right)^{1/\alpha},
          & 0 \leq x \leq e/(\alpha + e) \\
          - \ln [((1/\alpha) + (1/e))(1 - x)],
          & e/(\alpha + e) < x \leq 1.
        \end{cases}
      \end{align*}
      On remarque que
      \begin{displaymath}
        \frac{f_X(x)}{c g_Y(x)} =
        \begin{cases}
          e^{-x},        & 0 \leq x \leq 1 \\
          x^{\alpha - 1}, & x > 1.
        \end{cases}
      \end{displaymath}
      On a donc l'algorithme de simulation suivant:
      \begin{enumerate}[1.]
      \item Simuler deux nombres $u_1$ et $u_2$ d'une $U(0, 1)$.
      \item Poser $y = G_Y^{-1}(u_1)$.
      \item Si
        \begin{displaymath}
          u_2 \leq
          \begin{cases}
            e^{-y},        & 0 \leq y \leq 1 \\
            y^{\alpha - 1}, & y > 1,
          \end{cases}
        \end{displaymath}
        alors poser $x = y$. Sinon, retourner à l'étape 1.
      \end{enumerate}
    \end{enumerate}
  \end{sol}
\end{exercice}

\begin{exercice}
  On vous donne l'inégalité suivante, valide pour $\alpha \geq 1$:
  \begin{displaymath}
    x^{\alpha - 1} e^{-x}
    \leq \alpha^{\alpha - 1} e^{-x/\alpha + 1 -  \alpha}, \quad x > 0.
  \end{displaymath}
  Utiliser cette inégalité pour justifier l'algorithme
  d'acceptation-rejet suivant pour simuler des observations d'une loi
  Gamma$(\alpha, 1)$ avec $\alpha \geq 1$:
  \begin{enumerate}[1.]
  \item Simuler deux observations indépendantes $v_1$ et $v_2$ d'une
    loi exponentielle de moyenne $1$.
  \item Si $v_2 < (\alpha - 1)(v_1 - \ln v_1 - 1)$, poser $x =
    \alpha v_1$. Sinon, retourner à l'étape 1.
  \end{enumerate}
  \begin{sol}
    On veut simuler des observations de la fonction de densité de
    probabilité $f_X(x) = x^{\alpha - 1} e^{-x}/\Gamma(\alpha)$ avec
    $\alpha \geq 1$. Or, on nous donne
    \begin{displaymath}
      f_X(x) \leq \frac{\alpha^\alpha}{\Gamma(\alpha)}\,
      e^{1 - \alpha}\,
      \frac{1}{\alpha}\, e^{-x/\alpha}, \quad x > 0,
    \end{displaymath}
    d'où $f_X(x) \leq c g_Y(x)$ avec
    \begin{align*}
      c
      &= \frac{\alpha^\alpha}{\Gamma(\alpha)}\, e^{1 - \alpha} \\
      \intertext{et}
      g_Y(x)
      &= \frac{1}{\alpha}\, e^{-x/\alpha}.
    \end{align*}
    Ainsi, $Y \sim \text{Exponentielle}(1/\alpha)$. Soit $y$ une
    observation de la variable aléatoire $Y$ et $u$ une observation
    d'une loi $U(0, 1)$. Selon l'algorithme d'acceptation-rejet, on
    accepte la valeur $y$ comme observation d'une loi Gamma$(\alpha,
    1)$ avec $\alpha \geq 1$ si
    \begin{gather*}
      u \leq \frac{f_X(y)}{c g_Y(y)} =
      y^{\alpha - 1}\, \frac{e^{-y (1 - 1/\alpha)}}{\alpha^{\alpha -
          1} e^{-(\alpha - 1)}} \\
      \Updownarrow \\
      u^{1/(\alpha - 1)} \leq \left( \frac{y}{\alpha} \right)
      \frac{e^{-y/\alpha}}{e^{-1}} \\
      \Updownarrow \\
      \ln u \leq (\alpha - 1)
      \left[
        \ln \left( \frac{y}{\alpha} \right) - \frac{y}{\alpha} + 1
      \right] \\
      \Updownarrow \\
      - \ln u > (\alpha - 1)
      \left[
        \frac{y}{\alpha} - \ln \left( \frac{y}{\alpha} \right) - 1
      \right].
    \end{gather*}
    Or, tant la distribution de $-\ln U$ que celle de $Y/\alpha$ est
    une exponentielle de moyenne $1$, d'où l'algorithme donné dans
    l'énoncé.
  \end{sol}
\end{exercice}

\Closesolutionfile{reponses}
\Closesolutionfile{solutions}

\input{reponses-simulation}

x%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "methodes-numeriques-en-actuariat_simulation"
%%% coding: utf-8
%%% End:
